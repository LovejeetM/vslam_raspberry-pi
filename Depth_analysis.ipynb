{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94de4c80",
   "metadata": {},
   "source": [
    "# code to render stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe5495a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install aiortc aiohttp --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc457314",
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiortc, aiohttp\n",
    "import asyncio, cv2, numpy as np, aiohttp, logging, base64\n",
    "from aiortc import RTCPeerConnection, RTCSessionDescription\n",
    "from aiortc.mediastreams import MediaStreamError\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "\n",
    "WHEP_URL = \"your stream url/whep\"\n",
    "DISPLAY_FPS = 15\n",
    "\n",
    "\n",
    "logging.getLogger(\"aiortc.codecs.h264\").setLevel(logging.ERROR)\n",
    "# logging.basicConfig(level=logging.WARNING)\n",
    "# logging.getLogger(\"aiortc\").setLevel(logging.WARNING)\n",
    "\n",
    "class WebRTCStreamViewer:\n",
    "    def __init__(self, whep_url):\n",
    "        self.whep_url = whep_url\n",
    "        self.pc = RTCPeerConnection()\n",
    "        self.done = asyncio.Event()\n",
    "        self.lock = asyncio.Lock()\n",
    "        self.latest_frame = None\n",
    "\n",
    "\n",
    "        @self.pc.on(\"track\")\n",
    "        async def on_track(track):\n",
    "            if track.kind == \"video\":\n",
    "                asyncio.create_task(self._frame_receiver_task(track))\n",
    "\n",
    "        @self.pc.on(\"connectionstatechange\")\n",
    "        async def on_connectionstatechange():\n",
    "            print(f\"Connection state is {self.pc.connectionState}\")\n",
    "            if self.pc.connectionState in [\"failed\", \"closed\", \"disconnected\"]:\n",
    "                self.done.set()\n",
    "\n",
    "\n",
    "    async def _frame_receiver_task(self, track):\n",
    "        while not self.done.is_set():\n",
    "            try:\n",
    "                frame = await track.recv()\n",
    "                img = frame.to_ndarray(format=\"bgr24\")\n",
    "                async with self.lock:\n",
    "                    self.latest_frame = img\n",
    "            except MediaStreamError:\n",
    "                return\n",
    "\n",
    "\n",
    "    async def _display_loop_task(self):\n",
    "        display_handle = display(HTML('<img>'), display_id=True)\n",
    "\n",
    "        while not self.done.is_set():\n",
    "            frame_to_display = None\n",
    "            async with self.lock:\n",
    "                if self.latest_frame is not None:\n",
    "\n",
    "                    frame_to_display = self.latest_frame.copy()\n",
    "\n",
    "            if frame_to_display is not None:\n",
    "                # --- DEPTH ANALYSIS CODE GOES HERE ---\n",
    "                processed_frame = frame_to_display\n",
    "                # ---\n",
    "\n",
    "\n",
    "                _, buffer = cv2.imencode('.jpg', processed_frame)\n",
    "                b64_str = base64.b64encode(buffer).decode('utf-8')\n",
    "                data_url = f\"data:image/jpeg;base64,{b64_str}\"\n",
    "                display_handle.update(HTML(f'<img src=\"{data_url}\" style=\"width: 80%;\" />'))\n",
    "\n",
    "\n",
    "            await asyncio.sleep(1 / DISPLAY_FPS)\n",
    "\n",
    "    async def run(self):\n",
    "        self.pc.addTransceiver(\"video\", direction=\"recvonly\")\n",
    "        offer = await self.pc.createOffer()\n",
    "        await self.pc.setLocalDescription(offer)\n",
    "\n",
    "        try:\n",
    "            display_task = asyncio.create_task(self._display_loop_task())\n",
    "            async with aiohttp.ClientSession() as session:\n",
    "                print(f\"Connecting to {self.whep_url}...\")\n",
    "                async with session.post(self.whep_url, data=self.pc.localDescription.sdp,\n",
    "                                        headers={\"Content-Type\": \"application/sdp\"}, timeout=15) as resp:\n",
    "                    if resp.status == 201:\n",
    "                        # print(\"WHEP connection accepted.\")\n",
    "                        answer_sdp = await resp.text()\n",
    "                        await self.pc.setRemoteDescription(RTCSessionDescription(sdp=answer_sdp, type=\"answer\"))\n",
    "                    else:\n",
    "                        # print(f\"Server error: {resp.status} {await resp.text()}\")\n",
    "                        self.done.set()\n",
    "\n",
    "\n",
    "            await self.done.wait()\n",
    "\n",
    "        finally:\n",
    "            # print(\"Shutting down\")\n",
    "            if 'display_task' in locals() and not display_task.done():\n",
    "                display_task.cancel()\n",
    "            if self.pc.connectionState != \"closed\":\n",
    "                await self.pc.close()\n",
    "\n",
    "async def main():\n",
    "    viewer = WebRTCStreamViewer(WHEP_URL)\n",
    "    await viewer.run()\n",
    "\n",
    "try:\n",
    "    await main()\n",
    "    # asyncio.run(main())\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nStream stopped.\")\n",
    "except asyncio.CancelledError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da74c8b6",
   "metadata": {},
   "source": [
    "# Applying Depth-Estimation on stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c50897",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install transformers torch torchvision accelerate aiortc aiohttp accelerate Pillow --quiet\n",
    "\n",
    "import asyncio, cv2, numpy as np, aiohttp, logging, base64, torch\n",
    "from aiortc import RTCPeerConnection, RTCSessionDescription\n",
    "from aiortc.mediastreams import MediaStreamError\n",
    "from IPython.display import display, HTML\n",
    "from PIL import Image\n",
    "from transformers import AutoImageProcessor, AutoModelForDepthEstimation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a10d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    checkpoint = \"apple/DepthPro-hf\"    # It is slower on gpu but it gives great outputs\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    dtype = torch.float16 if device == \"cuda\" else torch.float32\n",
    "    print(f\"Loading model on device: '{device}' with dtype: {dtype}\")\n",
    "\n",
    "    image_processor = AutoImageProcessor.from_pretrained(checkpoint)\n",
    "    depth_model = AutoModelForDepthEstimation.from_pretrained(\n",
    "        checkpoint,\n",
    "        torch_dtype=dtype,\n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "    print(\"Depth Pro model and processor loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to load model: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5991555",
   "metadata": {},
   "outputs": [],
   "source": [
    "WHEP_URL = \"Your url route/whep\"\n",
    "DISPLAY_FPS = 15    # fixed stream fps for colab, otherwise colab starts to lag\n",
    "\n",
    "logging.getLogger(\"libav\").setLevel(logging.CRITICAL)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class WebRTCStreamViewer:\n",
    "    def __init__(self, whep_url, processor, model, device, dtype):\n",
    "        self.whep_url = whep_url\n",
    "        self.processor = processor\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.dtype = dtype\n",
    "        self.pc = RTCPeerConnection()\n",
    "        self.done = asyncio.Event()\n",
    "        self.lock = asyncio.Lock()\n",
    "        self.latest_frame = None\n",
    "        self.video_ssrc = None\n",
    "\n",
    "        @self.pc.on(\"track\")\n",
    "        async def on_track(track):\n",
    "            if track.kind == \"video\":\n",
    "                receiver = next((r for r in self.pc.getReceivers() if r.track == track), None)\n",
    "                if receiver and receiver.getSynchronizationSources():\n",
    "                    self.video_ssrc = receiver.getSynchronizationSources()[0].ssrc\n",
    "                    asyncio.create_task(self._keyframe_requester_task())\n",
    "                asyncio.create_task(self._frame_receiver_task(track))\n",
    "\n",
    "        @self.pc.on(\"connectionstatechange\")\n",
    "        async def on_connectionstatechange():\n",
    "            if self.pc.connectionState in [\"failed\", \"closed\", \"disconnected\"]:\n",
    "                self.done.set()\n",
    "\n",
    "    async def _keyframe_requester_task(self):\n",
    "        while not self.done.is_set():\n",
    "            async with self.lock:\n",
    "                if self.latest_frame is not None:\n",
    "                    break\n",
    "            if self.video_ssrc:\n",
    "                try:\n",
    "                    await self.pc.sendFeedback(ssrc=self.video_ssrc, fmt=1)\n",
    "                except Exception:\n",
    "                    pass\n",
    "            await asyncio.sleep(1)\n",
    "\n",
    "    async def _frame_receiver_task(self, track):\n",
    "        while not self.done.is_set():\n",
    "            try:\n",
    "                frame = await track.recv()\n",
    "                img = frame.to_ndarray(format=\"bgr24\")\n",
    "                async with self.lock:\n",
    "                    self.latest_frame = img\n",
    "            except MediaStreamError:\n",
    "                await asyncio.sleep(0.01)\n",
    "                continue\n",
    "            except Exception:\n",
    "                self.done.set()\n",
    "                break\n",
    "\n",
    "    async def _display_loop_task(self):\n",
    "        display_handle = display(HTML('<img>'), display_id=True)\n",
    "        while not self.done.is_set():\n",
    "            frame_to_display = None\n",
    "            async with self.lock:\n",
    "                if self.latest_frame is not None:\n",
    "                    frame_to_display = self.latest_frame.copy()\n",
    "\n",
    "            if frame_to_display is not None:\n",
    "                original_h, original_w, _ = frame_to_display.shape\n",
    "                rgb_image = Image.fromarray(cv2.cvtColor(frame_to_display, cv2.COLOR_BGR2RGB))\n",
    "                inputs = self.processor(images=rgb_image, return_tensors=\"pt\")\n",
    "                pixel_values = inputs.pixel_values.to(self.device, dtype=self.dtype)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    outputs = self.model(pixel_values)\n",
    "                    predicted_depth = outputs.predicted_depth\n",
    "\n",
    "                prediction = torch.nn.functional.interpolate(\n",
    "                    predicted_depth.unsqueeze(1),\n",
    "                    size=(original_h, original_w),\n",
    "                    mode=\"bicubic\",\n",
    "                    align_corners=False,\n",
    "                ).squeeze()\n",
    "\n",
    "                output = prediction.cpu().numpy()\n",
    "                formatted = (output * 255 / np.max(output)).astype(\"uint8\")\n",
    "                depth_colormap = cv2.applyColorMap(formatted, cv2.COLORMAP_JET)\n",
    "                combined_frame = np.hstack((frame_to_display, depth_colormap))\n",
    "\n",
    "                _, buffer = cv2.imencode('.jpg', combined_frame)\n",
    "                b64_str = base64.b64encode(buffer).decode('utf-8')\n",
    "                data_url = f\"data:image/jpeg;base64,{b64_str}\"\n",
    "                display_handle.update(HTML(f'<img src=\"{data_url}\" style=\"width: 80%;\" />'))\n",
    "\n",
    "            await asyncio.sleep(1 / DISPLAY_FPS)\n",
    "\n",
    "    async def run(self):\n",
    "        self.pc.addTransceiver(\"video\", direction=\"recvonly\")\n",
    "        offer = await self.pc.createOffer()\n",
    "        await self.pc.setLocalDescription(offer)\n",
    "\n",
    "        try:\n",
    "            display_task = asyncio.create_task(self._display_loop_task())\n",
    "            async with aiohttp.ClientSession() as session:\n",
    "                async with session.post(self.whep_url, data=self.pc.localDescription.sdp,\n",
    "                                        headers={\"Content-Type\": \"application/sdp\"}, timeout=15) as resp:\n",
    "                    if resp.status == 201:\n",
    "                        answer_sdp = await resp.text()\n",
    "                        await self.pc.setRemoteDescription(RTCSessionDescription(sdp=answer_sdp, type=\"answer\"))\n",
    "                    else:\n",
    "                        self.done.set()\n",
    "            await self.done.wait()\n",
    "        finally:\n",
    "            if 'display_task' in locals() and not display_task.done():\n",
    "                display_task.cancel()\n",
    "            if self.pc.connectionState != \"closed\":\n",
    "                await self.pc.close()\n",
    "\n",
    "async def main():\n",
    "    viewer = WebRTCStreamViewer(WHEP_URL, image_processor, depth_model, device, dtype)\n",
    "    await viewer.run()\n",
    "\n",
    "try:\n",
    "    await main()\n",
    "except (KeyboardInterrupt, asyncio.CancelledError):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ae844f",
   "metadata": {},
   "source": [
    "# Using GLPN Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e8b279",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install transformers torch torchvision accelerate aiortc aiohttp Pillow --quiet\n",
    "\n",
    "import asyncio, cv2, numpy as np, aiohttp, logging, base64, torch\n",
    "from aiortc import RTCPeerConnection, RTCSessionDescription\n",
    "from aiortc.mediastreams import MediaStreamError\n",
    "from IPython.display import display, HTML\n",
    "from PIL import Image\n",
    "from transformers import GLPNImageProcessor, GLPNForDepthEstimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7bc1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "WHEP_URL = \"Your stream url/whep\"\n",
    "DISPLAY_FPS = 30      # increased stream fps \n",
    "CHECKPOINT = \"vinvino02/glpn-kitti\"       # Runs really fast on gpu but less output quality\n",
    "# vinvino02/glpn-nyu   is also really fast and gives better output than glpn-kitti\n",
    "# Intel/intel-dpt-large  is also great but runs slower\n",
    "\n",
    "logging.getLogger(\"libav\").setLevel(logging.CRITICAL)\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "dtype = torch.float16 if device == \"cuda\" else torch.float32\n",
    "\n",
    "try:\n",
    "    print(f\"Loading model '{CHECKPOINT}' on device: '{device}' with dtype: {dtype}\")\n",
    "    image_processor = GLPNImageProcessor.from_pretrained(CHECKPOINT)\n",
    "    depth_model = GLPNForDepthEstimation.from_pretrained(CHECKPOINT).to(device, dtype=dtype)\n",
    "    print(\"Model and processor loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to load model: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223e0c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebRTCStreamViewer:\n",
    "    def __init__(self, whep_url, processor, model, device, dtype):\n",
    "        self.whep_url = whep_url\n",
    "        self.processor = processor\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.dtype = dtype\n",
    "        self.pc = RTCPeerConnection()\n",
    "        self.done = asyncio.Event()\n",
    "        self.lock = asyncio.Lock()\n",
    "        self.latest_frame = None\n",
    "        self.video_track = None\n",
    "        asyncio.create_task(self._keyframe_watchdog_task())\n",
    "\n",
    "        @self.pc.on(\"track\")\n",
    "        async def on_track(track):\n",
    "            if track.kind == \"video\":\n",
    "                self.video_track = track\n",
    "                asyncio.create_task(self._frame_receiver_task(track))\n",
    "\n",
    "        @self.pc.on(\"connectionstatechange\")\n",
    "        async def on_connectionstatechange():\n",
    "            if self.pc.connectionState in [\"failed\", \"closed\", \"disconnected\"]:\n",
    "                self.done.set()\n",
    "\n",
    "    async def _keyframe_watchdog_task(self):\n",
    "        await asyncio.sleep(0.1)\n",
    "        while self.pc.connectionState != \"connected\":\n",
    "            if self.done.is_set(): return\n",
    "            await asyncio.sleep(0.1)\n",
    "        \n",
    "        video_ssrc = None\n",
    "        while video_ssrc is None:\n",
    "            if self.done.is_set() or self.video_track is None: return\n",
    "            receiver = next((r for r in self.pc.getReceivers() if r.track == self.video_track), None)\n",
    "            if receiver and receiver.getSynchronizationSources():\n",
    "                video_ssrc = receiver.getSynchronizationSources()[0].ssrc\n",
    "                break\n",
    "            await asyncio.sleep(0.5)\n",
    "\n",
    "        while not self.done.is_set():\n",
    "            async with self.lock:\n",
    "                if self.latest_frame is not None: return\n",
    "            try:\n",
    "                await self.pc.sendFeedback(ssrc=video_ssrc, fmt=1)\n",
    "            except Exception: pass\n",
    "            await asyncio.sleep(1)\n",
    "\n",
    "    async def _frame_receiver_task(self, track):\n",
    "        while not self.done.is_set():\n",
    "            try:\n",
    "                frame = await track.recv()\n",
    "                img = frame.to_ndarray(format=\"bgr24\")\n",
    "                async with self.lock:\n",
    "                    self.latest_frame = img\n",
    "            except MediaStreamError:\n",
    "                await asyncio.sleep(0.01)\n",
    "                continue\n",
    "            except Exception:\n",
    "                self.done.set()\n",
    "                break\n",
    "\n",
    "    async def _display_loop_task(self):\n",
    "        display_handle = display(HTML('<img>'), display_id=True)\n",
    "        while not self.done.is_set():\n",
    "            frame_to_display = None\n",
    "            async with self.lock:\n",
    "                if self.latest_frame is not None:\n",
    "                    frame_to_display = self.latest_frame.copy()\n",
    "\n",
    "            if frame_to_display is not None:\n",
    "                original_h, original_w, _ = frame_to_display.shape\n",
    "                rgb_image = Image.fromarray(cv2.cvtColor(frame_to_display, cv2.COLOR_BGR2RGB))\n",
    "                \n",
    "                inputs = self.processor(images=rgb_image, return_tensors=\"pt\").to(self.device)\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    outputs = self.model(**inputs)\n",
    "                    predicted_depth = outputs.predicted_depth\n",
    "\n",
    "                prediction = torch.nn.functional.interpolate(\n",
    "                    predicted_depth.unsqueeze(1),\n",
    "                    size=(original_h, original_w),\n",
    "                    mode=\"bicubic\",\n",
    "                    align_corners=False,\n",
    "                ).squeeze()\n",
    "\n",
    "                output = prediction.cpu().numpy()\n",
    "                formatted = ((output - output.min()) * 255 / (output.max() - output.min())).astype(\"uint8\")\n",
    "                \n",
    "                depth_colormap = cv2.applyColorMap(formatted, cv2.COLORMAP_JET)\n",
    "                \n",
    "                combined_frame = np.hstack((frame_to_display, depth_colormap))\n",
    "\n",
    "                _, buffer = cv2.imencode('.jpg', combined_frame)\n",
    "                b64_str = base64.b64encode(buffer).decode('utf-8')\n",
    "                data_url = f\"data:image/jpeg;base64,{b64_str}\"\n",
    "                display_handle.update(HTML(f'<img src=\"{data_url}\" style=\"width: 80%;\" />'))\n",
    "\n",
    "            await asyncio.sleep(1 / DISPLAY_FPS)\n",
    "\n",
    "    async def run(self):\n",
    "        self.pc.addTransceiver(\"video\", direction=\"recvonly\")\n",
    "        offer = await self.pc.createOffer()\n",
    "        await self.pc.setLocalDescription(offer)\n",
    "        try:\n",
    "            display_task = asyncio.create_task(self._display_loop_task())\n",
    "            async with aiohttp.ClientSession() as session:\n",
    "                async with session.post(self.whep_url, data=self.pc.localDescription.sdp,\n",
    "                                        headers={\"Content-Type\": \"application/sdp\"}, timeout=15) as resp:\n",
    "                    if resp.status == 201:\n",
    "                        answer_sdp = await resp.text()\n",
    "                        await self.pc.setRemoteDescription(RTCSessionDescription(sdp=answer_sdp, type=\"answer\"))\n",
    "                    else:\n",
    "                        self.done.set()\n",
    "            await self.done.wait()\n",
    "        finally:\n",
    "            if 'display_task' in locals() and not display_task.done():\n",
    "                display_task.cancel()\n",
    "            if self.pc.connectionState != \"closed\":\n",
    "                await self.pc.close()\n",
    "\n",
    "async def main():\n",
    "    viewer = WebRTCStreamViewer(WHEP_URL, image_processor, depth_model, device, dtype)\n",
    "    await viewer.run()\n",
    "\n",
    "try:\n",
    "    await main()\n",
    "except (KeyboardInterrupt, asyncio.CancelledError):\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
